---
title: "Projekt 1 etap 3"
author: "Adrianna Wlazło, Patrycja Faszczewska"
date: "7 grudnia 2016"
output: html_document
---


```{r load, message=FALSE, warning=FALSE, results="hide", echo=FALSE}
#wklej sciezke
path <- "C:\\Users\\adawl\\Documents\\eRowe rzeczy\\statystyka II\\projekt\\faza 3\\wektory"

#cancer
load(file=paste0(path,"\\cancer.rda"))

#funkcje
load(file=paste0(path,"\\funkcje.RData"))

#zbiory testowe
load(file=paste0(path,"\\zbiory.rda"))

#tablice predykcji
load(file=paste0(path,"\\wszystkie_tab.RData"))


cancer$smierc <- as.factor(ifelse(cancer$death1y=="dead",0,1))
wybrane<-c("SLC17A9", "PLAUR", "LRRC6", "CLEC5A", "TBL1XR1", "BHLHE40",
           "CTSB", "LSP1","NRG1", "AQP9", "CSNK1D", "HK3", "ACTR3C","age", "SLC11A1","TM7SF4", "CTF1", "GPNMB", "MLPH", "STC1", "C8orf58", "CPPED1", "CTSD", "MAP2K3", "NCF2","TNFSF14","ZC3H12A", "LILRB3", "SLC6A6")

#biblioteki
library("caret")
library("glmnet")
library("gbm")
library("adabag")
library("xgboost")
library("randomForest")
library("ggplot2")
library("pROC")
library("ROCR")
library("RColorBrewer")

```


```{r f1.obtain, message=FALSE, warning=FALSE, results="hide", echo=FALSE}
f_ada <- kaggle_f1(obserwacje(zbiory),tab_ada)
f_bagging<- kaggle_f1(obserwacje(zbiory),tab_bagging)
f_elastic<- kaggle_f1(obserwacje(zbiory),tab_elastic)
f_las<- kaggle_f1(obserwacje(zbiory),tab_las)
f_lasso<- kaggle_f1(obserwacje(zbiory),tab_lasso)
f_ridge<- kaggle_f1(obserwacje(zbiory),tab_ridge)
f_xgboost<- kaggle_f1(obserwacje(zbiory),tab_xgboost)


#majority votes
tab_srednia1<-matrix(NA,nrow=nrow(tab_ada),ncol=100)
for (i in 1:100){
  tab_srednia1[,i]<-round((as.numeric(tab_ada[,i])+as.numeric(tab_las[,i])+as.numeric(tab_elastic[,i]))/3-1,digits=0)
}
tab_srednia<-as.data.frame(tab_srednia1)
f_srednia<-kaggle_f1(obserwacje(zbiory),tab_srednia)

#demokracja z ada
tab_dem <- matrix(NA,nrow=nrow(tab_ada),ncol=100)
for (i in 1:100){
  tab_dem[,i] <- ifelse(tab_lasso[,i]==tab_bagging[,i] & tab_lasso[,i]==tab_xgboost[,i],
                        tab_lasso[,i],
                        tab_ada[,i])
}
tab_dem <- as.data.frame(tab_dem)
f_dem <- kaggle_f1(obserwacje(zbiory),tab_dem)
```


```{r mse.obtain, message=FALSE, warning=FALSE, results="hide", echo=FALSE}
mse_ada <- MSE(obserwacje(zbiory),tab_ada)
mse_bagging<- MSE(obserwacje(zbiory),tab_bagging)
mse_elastic<- MSE(obserwacje(zbiory),tab_elastic)
mse_las<- MSE(obserwacje(zbiory),tab_las)
mse_lasso<- MSE(obserwacje(zbiory),tab_lasso)
mse_ridge<- MSE(obserwacje(zbiory),tab_ridge)
mse_xgboost<- MSE(obserwacje(zbiory),tab_xgboost)
mse_srednia<-MSE(obserwacje(zbiory),tab_srednia+1)
mse_dem <- MSE(obserwacje(zbiory),tab_dem)
```

```{r pola.roc.obtain, message=FALSE, warning=FALSE, results="hide", echo=FALSE}
pr_ada <- pole_roc(zbiory,tab_ada)
pr_bagging<- pole_roc(zbiory,tab_bagging)
pr_elastic<- pole_roc(zbiory,tab_elastic)
pr_las<- pole_roc(zbiory,tab_las)
pr_lasso<- pole_roc(zbiory,tab_lasso)
pr_ridge<- pole_roc(zbiory,tab_ridge)
pr_xgboost<- pole_roc(zbiory,tab_xgboost)
pr_srednia<-pole_roc(zbiory,tab_srednia)
pr_dem <- pole_roc(zbiory,tab_dem)
```

```{r cv.load, message=FALSE, warning=FALSE, results="hide", echo=FALSE}
load(file=paste0(path,"\\wszystkie_bledy_cv125.RData"))
```


#Ocena klasyfikatorów
Ocenę przeprowadzimy przy podziale na modele regresjii i modele typu boosting/bagging. Wylosujemy 100 razy zbiór testowy zawierający 75% zbioru wejściowego, z zachowaniem proporcji pacjentów o różnych stanach po roku. Porównywanie wszystkich klasyfikatorów zastosujemy na tej samej próbie zbiorów testowych. Jakość otrzymanych klasyfikatorów zbadamy w oparciu o współczynnik stosowany w kaggle,błąd w krosswalidacji, pole pod krzywą ROC oraz błąd MSE.

##Modele regresji (lasso, ridge, elastic net)
W celu uniknięcia przeuczenia modelu regresji liniowej zregularyzujemy regresję 3 metodami: lasso, ridge oraz elastic net. W efekcie przeprowadzonej analizy wybierzemy najskuteczniejszą z metod regularyzacji dla prezentowanego modelu, która posłuży nam do zbudowania modelu opartego o kilka najlepszych klasyfikatorów.

###Błąd średniokwadratowy
Przydatne może być porównanie błędu średniokwadratowego dla różnych lambd w każdym z modeli. Spójrzmy zatem na wykresy przedstawiające MSE dla każdego z klasyfikatorów w zależności od wartości lambdy ograniczającej współczynniki w modelu regresji:
<br></br>
```{r,echo=FALSE,warning=FALSE}
inTrain<-unlist(zbiory[1])

ridge1<-cv.glmnet(as.matrix(cancer[inTrain,wybrane]),
                      as.numeric(cancer[inTrain,"smierc"])-1,
                      type.measure="mse",
                      family="binomial",alpha=0)
plot(ridge1,xvar="lambda", main="Rozkład MSE dla różnych lambd - metoda ridge \n \n ", ylim=c(0.3,0.7), xlim=c(-3.6,5.3))
lasso1<-cv.glmnet(as.matrix(cancer[inTrain,wybrane]),
                      as.numeric(cancer[inTrain,"smierc"])-1,
                      type.measure="mse",
                      family="binomial",alpha=1)
plot(lasso1,xvar="lambda", main="Rozkład MSE dla różnych lambd - metoda lasso \n \n ", ylim=c(0.3,0.7), xlim=c(-8.6,-1))
enfit1<-cv.glmnet(as.matrix(cancer[inTrain,wybrane]),
                      as.numeric(cancer[inTrain,"smierc"])-1,
                      type.measure="mse",
                      family="binomial",alpha=0.5)
plot(enfit1, main="Rozkład MSE dla różnych lambd - metoda elastic net \n \n ", ylim=c(0.3,0.7), xlim=c(-8.6,-1))
```
<br></br>Jak widzimy wykresy te są podobne w przypadku regularyzacji lasso i elastic net. Jak później pokażemy metody te mają podobną skutecznośc w przypadku prezentowanego problemu i miar jakości klasyfikacji, które zdecydowałyśmy się zastosować.

###Miara dopasowania z platformy Kaggle
Warto przyjrzeć się, jakie wyniki potencjalnie można uzyskać każdą z metod na platformie Kaggle. Współczynnik f1 mierzy wartości "precision" i "recall" i faworyzyje takie predykcje, gdzie owe miary są do siebie jak najbardziej zbliżone.
Poniżej przedstawiamy rozkłady miary f1 w zależności od metody:
<br></br>
```{r, message=FALSE, warning=FALSE, echo=FALSE}
wspol<- as.data.frame(list(c(replicate(length(f_lasso),"lasso"),    
                            replicate(length(f_ridge),"ridge"),
                            replicate(length(f_elastic),"elastic net")),
                           c(f_lasso,f_ridge,f_elastic)), col.names=c("metoda","f1"))


wspol$metoda <- reorder(wspol$metoda,-wspol$f1,median)
v <- levels(wspol$metoda)
ggplot(wspol, aes(x=metoda, y=f1, fill=metoda))+geom_boxplot() + ggtitle("Rozkład miary dopasowania - wg mediany malejąco") + theme_bw() + scale_fill_manual(values = kolory(v), labels=v)

wspol$metoda <- reorder(wspol$metoda,wspol$f1,sd)
v <- levels(wspol$metoda)
ggplot(wspol, aes(x=metoda, y=f1, fill=metoda))+geom_boxplot() +ggtitle("Rozkład miary dopasowania - wg odch. std. rosnąco") + theme_bw() + scale_fill_manual(values = kolory(v), labels=v)

```
<br></br>
Pierwszy z przedstawionych wykresów prezentuje wybrane metody w kolejności malejącej biorąc pod uwagę medianę rozkładu, natomiast drugi pod względem odchylenia standardowego. Wykresy te są wygodne w interpretacji. Im wyższa wartość f1 tym model lepiej przewidywał dane (uzyskane rozkłady wskaźników otrzymane są przy 100-krotnym losowaniu zbioru uczącego). Zatem rozkład współczynnika sugeruje wybór elastic net bądź lasso.

###Pole pod krzywą ROC
Kolejnym narzędziem porównywania klasyfikatorów jest pole pod krzywą ROC dla miar "specifity" i "sensitivity". Im wyższe pole tym lepszy klasyfikator. Wykresy krzywych ROC dla prezentowanych klasyfikatorów wyglądają następująco:
<br></br>
```{r krzyweROC_reg, message=FALSE, warning=FALSE, echo=FALSE}
inTrain<-unlist(zbiory[1])

krzywa1 <- prediction(as.numeric(tab_lasso[,1])-1,cancer[-inTrain,"smierc"])
perf1 <- performance(krzywa1,"sens","spec")
plot(perf1,ylim=c(0,1),col="red3", lwd=2)


krzywa2 <- prediction(as.numeric(tab_ridge[,1])-1,cancer[-inTrain,"smierc"])
perf2 <- performance(krzywa2,"sens","spec")
plot(perf2,col="purple3",lwd=2, add=TRUE)

krzywa3 <- prediction(as.numeric(tab_elastic[,1])-1,cancer[-inTrain,"smierc"])
perf3 <- performance(krzywa3,"sens","spec")
plot(perf3,col="black",lwd=2, add=TRUE)

legend("bottom",  ncol=1, legend=c("lasso","ridge","elastic net"), lty = 1, col = c("red3","purple3","black"), lwd=3)


```
<br></br>
Zbadajmy, jak zachowuje się pole pod krzywą ROC na 100 replikacjach zbioru testowego dla każdego z klasyfikatorów. Osiągnięte rezultaty prezentujemy poniżej.
<br></br>
```{r pole_koncowe_reg, echo=FALSE}
cat("Średnie pola pod wykresem krzywej ROC:\n",
    mean(pr_ridge),"  Ridge\n",
    mean(pr_lasso),"  Lasso\n",
    mean(pr_elastic),"  Elastic net\n")

```
W przypadku metody elastic net i lasso pole pod wykresem krzywej ROC w średniej osiąga poziom 0.729 czyli 0.13 więcej niż pole pod wykresem ROC dla funkcji ridge.

###Cross walidacja
Porównamy również błędy otrzymane podczas przeprowadzania crosswalidacji.(N-fold cv) Ze względu na mały rozmiar danych przeprowadzimy N-fold crosswalidacje. Jej wyniki prezentujemy poniżej.
<br></br>

```{r srednie_koncowe_reg, echo=FALSE, message=FALSE, warning=FALSE}

trafnosci <- as.data.frame(list(c(blad_ridge,blad_lasso,blad_elastic),
                                c(replicate(length(blad_ridge),"ridge"),
                                  replicate(length(blad_lasso),"lasso"),
                                  replicate(length(blad_elastic),"elastic"))),
                           col.names=c("blad","metoda"))

barplot(table((trafnosci$blad+1/4)^2,trafnosci$metoda), col=c("green4","red3","orange2"), border=c("green4","red3","orange2"),ylim=c(0,90), xpd=FALSE, main="Wyniki walidacji krzyżowej", beside=TRUE)

legend("topright",  ncol=1, legend=c("trafne","fp","fn"), fill=c("green4","red3","orange2"))

cat("Średnie błędy klasyfikatorów otrzymane w crosswalidacji:\n",
    mean(abs(blad_ridge)),"  Ridge\n",
    mean(abs(blad_lasso)),"  Lasso\n",
    mean(abs(blad_elastic)),"  Elastic net")
```
<br></br>
Po raz kolejny otrzymujemy podobną jakość w przypadku elastic net i lasso, które osiągneły mniejszy błąd aniżeli regularyzacja ridge. Bład ten utrzymuje się na poziomie ok. 26%.

##Metody adaboost,xgboost,bagging i random forest
Analogiczną analizę przeprowadzimy dla metod boosting/bagging. Metody te oparte są o komitety innych reguł i mają na celu obniżenie obciążenia/wariancji błędu predykcji. Prezentowane przez nas modele konstruujemy za pomocą funkcji adaboost, xgboost (boosting) oraz bagging, random forest (bagging).

###Błąd średniokwadratowy
Podobnie jak wcześniej pierwszą miarą, która zastosujemy w celu porównania wyżej wspomnianych funkcji jest błąd średniokwadratowy. Tym razem porówname rozkład MSE otrzymany przy 100-krotnym wylosowaniu zbioru uczącego. 
```{r mse_ada, message=FALSE, warning=FALSE, results="hide", echo=FALSE}
mse<- as.data.frame(list(c(replicate(length(mse_ada),"adaboost"),    
                           replicate(length(mse_xgboost),"xgboost"),
                           replicate(length(mse_bagging),"bagging"),
                           replicate(length(mse_las),"las losowy")),
                         c(mse_ada,mse_xgboost,mse_bagging, mse_las)),
                    col.names=c("metoda","blad"))


mse$metoda <- reorder(mse$metoda,mse$blad,median)
v <- levels(mse$metoda)
ggplot(mse, aes(x=metoda, y=blad, fill=metoda))+geom_boxplot() +ggtitle("Rozkład MSE wg metod - wg mediany rosnąco") + theme_bw() + scale_fill_manual(values = kolory(v), labels=v)

```

```{r mse_srednie_ada, message=FALSE, warning=FALSE, echo=FALSE}
cat("Błąd średniokwadratowy:\n",
    mean(abs(mse_ada)), " adaboost\n",
    mean(abs(mse_las)), "las losowy\n",
    mean(abs(mse_bagging)), "bagging\n",
    mean(abs(mse_xgboost)), "xgboost\n"
)
```

<br></br>
Analiza błędu średniokwadratowego wskazuje na wybór metody lasóW losowych oraz adaboost - mają one stosunkowo mały i dość stabilny MSE.


###Współczynnik dopasowania z platformy Kaggle
Kolejnym krokiem analizy będzie porównanie współczynnika stosowanego na platformie Kaggle.
```{r f1_ada, message=FALSE, warning=FALSE, results="hide", echo=FALSE}
wspol<- as.data.frame(list(c(replicate(length(f_ada),"adaboost"),    
                            replicate(length(f_xgboost),"xgboost"),
                            replicate(length(f_bagging),"bagging"),
                            replicate(length(f_las),"las losowy")),
                           c(f_ada,f_xgboost,f_bagging, f_las)), col.names=c("metoda","f1"))


wspol$metoda <- reorder(wspol$metoda,-wspol$f1,median)
v <- levels(wspol$metoda)
ggplot(wspol, aes(x=metoda, y=f1, fill=metoda))+geom_boxplot() + ggtitle("Rozkład miary dopasowania - wg mediany malejąco") + theme_bw() + scale_fill_manual(values = kolory(v), labels=v)

wspol$metoda <- reorder(wspol$metoda,wspol$f1,sd)
v <- levels(wspol$metoda)
ggplot(wspol, aes(x=metoda, y=f1, fill=metoda))+geom_boxplot() +ggtitle("Rozkład miary dopasowania - wg odch. std. rosnąco") + theme_bw() + scale_fill_manual(values = kolory(v), labels=v)
```
<br></br>
Powyższe wykresy przedstawiają rozkłady miary f1 dla różnych metod- pierwszy wg mediany malejaco, drugi wg odchylenia standardowego rosnąco. Na podstawie tej analizy skłaniamy się ku wyborze metody adaboost, ze względu na stosunkowo dobre dopasowanie przy zachowaniu mniejszego odchylenia.

###Pole pod krzywą ROC
Krzywe ROC dla wymienionych wyżej funkcji umieszczone są poniżej,
```{r krzyweROC_ada, message=FALSE, warning=FALSE, echo=FALSE}
inTrain<-unlist(zbiory[1])

krzywa1 <- prediction(as.numeric(tab_ada[,1]),cancer[-inTrain,"smierc"])
perf1 <- performance(krzywa1,"spec","sens")
plot(perf1,ylim=c(0,1),col="red3", lwd=2)

krzywa5 <- prediction(as.numeric(tab_xgboost[,1]),cancer[-inTrain,"smierc"])
perf5 <- performance(krzywa5,"spec","sens")
plot(perf5,col="purple3",lwd=2, add=TRUE)

krzywa3 <- prediction(as.numeric(tab_bagging[,1]),cancer[-inTrain,"smierc"])
perf3 <- performance(krzywa3,"spec","sens")
plot(perf3,col="orange2",lwd=2, add=TRUE)

krzywa4 <- prediction(as.numeric(tab_las[,1]),cancer[-inTrain,"smierc"])
perf4 <- performance(krzywa4,"spec","sens")
plot(perf4,col="black",lwd=2, add=TRUE)

#legenda
legend("bottom",  ncol=2, legend=c("adaboost","xgboost","bagging","las losowy"), lty = 1, col = c("red3","purple3","orange2","black"), lwd=2)

```

```{r sr_roc_ada, message=FALSE, warning=FALSE, echo=FALSE}
cat("Średnie pola pod wykresem krzywej ROC:\n",
    mean(pr_ada),"  Adaboost\n",
    mean(pr_las),"  Las losowy\n",
    mean(pr_xgboost),"  Xgboost\n",
    mean(pr_bagging),"  Bagging")
```

Największe średnie pole pod wykresem uzyskałyśmy dla metody lasu losowego, metoda adaboost jest na drugim miejscu. W przypadku funkcji xgboost oraz bagging pole pod wykresem wynosi średnio ok.0.70 i jest zdecydowanie słabszym rezultatem.

###Cross walidacja
Jak wcześniej przeprowadzimy 125-fold cross-walidacje w celu porównania średniej trafności predykcji.
```{r cv_ada, echo=FALSE, message=FALSE, warning=FALSE}
trafnosci <- as.data.frame(list(c(blad_ada,blad_las,blad_bagging,blad_xgboost),
                                c(replicate(length(blad_ada),"adaboost"),
                                  replicate(length(blad_las),"las losowy"),
                                  replicate(length(blad_bagging),"bagging"),
                                  replicate(length(blad_xgboost),"xgboost"))),
                           col.names=c("blad","metoda"))

barplot(table((trafnosci$blad+1/4)^2,trafnosci$metoda), col=c("green4","red3","orange2"), border=c("green4","red3","orange2"),ylim=c(0,90), xpd=FALSE, main="Błędy walidacji krzyżowej", beside=TRUE)

legend("topright",  ncol=1, legend=c("trafne","fp","fn"), fill=c("green4","red3","orange2"))

```

```{r srednie_konc_ada, echo=FALSE}
cat("Średnie błędy cross-walidacji:\n",
    mean(abs(blad_ada)), " adaboost\n",
    mean(abs(blad_las)), "las losowy\n",
    mean(abs(blad_bagging)), "bagging\n",
    mean(abs(blad_xgboost)), "xgboost\n"
)

```
<br></br>
Również 125-fold cross walidacja delikatnie wskazuje na mniejszą ilość pomyłek dla metody adaboost, która skutecznie przewidywała stan pacjenta po roku w ok. 72% przypadków.

##Konstrukcja modelu łączącego najlepsze z prezentowanych metod
<br></br>
W ostatnim kroku postaramy się połączyć najlepsze z prezentowanych metod aby skonstruować model, który najlepiej przewidzi stan pacjenta po roku. Konstrukcja ta będzie opierała się na funkcjach adaboost, las losowy oraz regularyzacja regresji liniowej elastic net. Zgodnie z przeprowadzoną analizą są to najlepsze klasyfikatory reprezentujące każde z podejść (regularyzację regresji, boosting, bagging).
<br></br> ("Majority voting") Końcowa predykcja w konstruowanym przez nas modelu będzie brała pod uwagę "głosy" każdej z wybranych funkcji i wybierała wartość która pojawi się  najczęściej. Oczywiście, aby ocenić tak skonstruowany model porównamy go z pozostałymi klasyfikatorami. Analiza ta pozwoli nam wyłonić najlepszy z prezentowanych przez nas modeli.
<br></br> Zdecydowałyśmy się również na zaprezentowanie metody predykcji, którą nazwałyśmy "demokracja".Model ten działa następująco: w przypadku zgodności predykcji modeli xgboost,lasso oraz bagging uznaje je za prawdziwe, natomiast gdy uzyskane w tych modelach predykcje różnią się to uznaje predykcję modelu adaboost za słuszną.

###Błąd średniokwadratowy
<br></br> Błąd średniokwadratowy dla najlepszych klasyfikatorów kształtuje się następująco:
```{r mse_k, message=FALSE, warning=FALSE, results="hide", echo=FALSE}
mse<- as.data.frame(list(c(replicate(length(mse_elastic),"elastic net"),
                           replicate(length(mse_ada),"adaboost"),
                           replicate(length(mse_las),"las losowy"),
                          replicate(length(mse_dem),"demokracja"),
                           replicate(length(mse_srednia),"majority votes")
                           ),
                         c(mse_elastic,mse_ada, mse_las,mse_dem, mse_srednia)),col.names=c("metoda","blad"))


mse$metoda <- reorder(mse$metoda,mse$blad,median)
v <- levels(mse$metoda)
ggplot(mse, aes(x=metoda, y=blad, fill=metoda))+geom_boxplot() +ggtitle("Rozkład MSE wg metod - wg mediany rosnąco") + theme_bw() + scale_fill_manual(values = kolory(v), labels=v)

```

```{r mse_srednie_k, message=FALSE, warning=FALSE, echo=FALSE}
cat("Błąd średniokwadratowy:\n",
    mean(abs(mse_elastic)), " elastic net\n",
    mean(abs(mse_ada)), " adaboost\n",
    mean(abs(mse_las)), " las losowy\n",
    mean(abs(mse_dem)), " demokracja\n",
    mean(abs(mse_srednia)), " majority votes\n"
)
```
<br></br>Najniższy błąd prezentuje las losowy. Natomiast drugi co do wielkości błąd średniokwadratowy ma wprowadzony tutaj model łączący pozostałe klasyfikatory, biorący pod uwagę przewidywania pozostałych klasyfikatorów.

###Miara dopasowania z platformy Kaggle
```{r f1_k, message=FALSE, warning=FALSE, results="hide", echo=FALSE}
wspol<- as.data.frame(list(c(replicate(length(f_elastic),"elastic net"),    
                            replicate(length(f_las),"las losowy"),
                            replicate(length(f_ada),"adaboost"),
                            replicate(length(f_dem),"demokracja"),
                            replicate(length(f_srednia),"majority votes")),
                           c(f_elastic,f_las,f_ada, f_dem,f_srednia)), col.names=c("metoda","f1"))


wspol$metoda <- reorder(wspol$metoda,-wspol$f1,median)
v <- levels(wspol$metoda)
ggplot(wspol, aes(x=metoda, y=f1, fill=metoda))+geom_boxplot() + ggtitle("Rozkład miary dopasowania - wg mediany malejąco") + theme_bw() + scale_fill_manual(values = kolory(v), labels=v)

wspol$metoda <- reorder(wspol$metoda,wspol$f1,sd)
v <- levels(wspol$metoda)
ggplot(wspol, aes(x=metoda, y=f1, fill=metoda))+geom_boxplot() +ggtitle("Rozkład miary dopasowania - wg odch. std. rosnąco") + theme_bw() + scale_fill_manual(values = kolory(v), labels=v)
```
<br></br>Wykresy prezentujące rozkład współczynnika f1 wyróżniają metody elastic net oraz majority votes.

###Pole pod krzywą ROC
```{r krzyweROC_k, message=FALSE, warning=FALSE, echo=FALSE}
inTrain<-unlist(zbiory[1])

krzywa11 <- prediction(as.numeric(tab_ada[,1]),cancer[-inTrain,"smierc"])
perf11 <- performance(krzywa11,"spec","sens")
plot(perf11,ylim=c(0,1),col="red", lwd=2)

krzywa12 <- prediction(as.numeric(tab_srednia[,1]),cancer[-inTrain,"smierc"])
perf12 <- performance(krzywa12,"spec","sens")
plot(perf12,col="purple3",lwd=2, add=TRUE)

krzywa13 <- prediction(as.numeric(tab_las[,1]),cancer[-inTrain,"smierc"])
perf13 <- performance(krzywa13,"spec","sens")
plot(perf13,col="black",lwd=2, add=TRUE)

krzywa15 <- prediction(as.numeric(tab_dem[,1]),cancer[-inTrain,"smierc"])
perf15 <- performance(krzywa15,"spec","sens")
plot(perf15,col="blue3",lwd=2, add=TRUE)

krzywa14 <- prediction(as.numeric(tab_elastic[,1]),cancer[-inTrain,"smierc"])
perf14 <- performance(krzywa14,"spec","sens")
plot(perf14,col="orange",lwd=2, add=TRUE)


#legenda
legend("bottom",  ncol=2, legend=c("adaboost","majority votes","las losowy","elastic net","demokracja"), lty = 1, col = c("red","purple3","black","orange","blue3"), lwd=2)

```

```{r sr_roc_k, message=FALSE, warning=FALSE, echo=FALSE}
cat("Średnie pola pod wykresem krzywej ROC:\n",
    mean(pr_elastic),"      Elastic net\n",
    mean(pr_ada),"  Adaboost\n",
    mean(pr_las),"  Las losowy\n",
    mean(pr_dem)," Demokracja \n",
    mean(pr_srednia),"  Majority votes")
```

<br></br> Najwyższe średnie pole pod wykresem krzywej ROC uzyskał las losowy, jednak niewiele mniejsze średnie pole uzyskała metoda "majority votes".

###Cross walidacja
```{r,warning=FALSE,results="hide",echo=FALSE}
blad_srednia<-round((blad_ada+blad_las+blad_elastic)/3,digits=0)

blad_dem <- ifelse(blad_bagging==blad_xgboost & blad_bagging==blad_lasso,
                   blad_bagging,blad_ada)

```

```{r cv_k, echo=FALSE, message=FALSE, warning=FALSE}
trafnosci <- as.data.frame(list(c(blad_ada,blad_las,blad_elastic,blad_dem,blad_srednia),
                                c(replicate(length(blad_ada),"adaboost"),
                                  replicate(length(blad_las),"las losowy"),
                                  replicate(length(blad_elastic),"elastic net"),
                                  replicate(length(blad_dem),"demokracja"),
                                  replicate(length(blad_srednia),"majority votes"))),
                           col.names=c("blad","metoda"))

barplot(table((trafnosci$blad+1/4)^2,trafnosci$metoda), col=c("green4","red3","orange2"), border=c("green4","red3","orange2"),ylim=c(0,90), xpd=FALSE, main="Błędy walidacji krzyżowej", beside=TRUE)

legend("topright",  ncol=1, legend=c("trafne","fp","fn"), fill=c("green4","red3","orange2"))

```

```{r srednie_konc_k, echo=FALSE}
cat("Średnie błędy cross-walidacji:\n",
    mean(abs(blad_ada)), " adaboost\n",
    mean(abs(blad_las)), "las losowy\n",
    mean(abs(blad_elastic)), "elastic net\n",
    mean(abs(blad_dem)), "demokracja\n",
    mean(abs(blad_srednia)), "majority votes\n"
)

```
<br></br> Najniższy średni błąd otrzymany w krosswalidacji należy do metod elastic net oraz "demokracja". Drugi co do wielkośći błąd należy do "majority votes".

<br></br>
<br></br>
Jak widzimy każda z przedstawionych miar wysoko plasuje model "majority votes" w porównaniu z pozostałymi klasyfikatorami, co skłania nas do wybory właśnie tej metody.