---
title: "Projekt1-etap2"
author: "Filip Binkiewicz, Wojciech Szymañski"
output: html_document
---

W tym etapie zajmiemy siê testowaniem ró¿nych klasyfikatorów. Najpierw wczytujemy dane Rak

```{r,message=FALSE,warning=FALSE}
load("C:/Users/ojro72/Desktop/Rak.rda")
```

W etapie 1 uzyskaliœmy zbiór istotnych cech, które teraz zapiszemy w wektorze `Nazwy`.
Nastepnie utworzymy `Zbiór_Cechy`, który bêdzie zawiera³ dane pacjentów z istotnymi cechami.  Zbudujemy klasyfikatory na zbiorze treningowym , natomiast w kolejnym kroku porównamy jakoœæ przeprowadzonych klasyfikacji.

```{r,message=FALSE,warning=FALSE}
Nazwy <- c("death1y","age","ACTR3C","AQP9","CLEC5A","CSNK1D","CTSB","CTSD","GPNMB","HK3","LRRC61","LSP1","MLPH","NCF2","NRG1","PLAUR","SLC11A1","SLC17A9","STAG2","STC1","TBL1XR1")

Zbior_Cechy <- Rak[,Nazwy]

library("caret")
wybor<-createDataPartition(as.factor(Zbior_Cechy$death1y), p=0.75, list=FALSE)

Zbior_Trening <- Zbior_Cechy[wybor,]
Zbior_Testowy <- Zbior_Cechy[-wybor,]


ZC <- Zbior_Cechy
ZC$death1y <- as.factor(Zbior_Cechy$death1y)
Zb <- Zbior_Trening
Zb$death1y <- as.factor(Zbior_Trening$death1y)
Zbt <- Zbior_Testowy
Zbt$death1y <- as.factor(Zbior_Testowy$death1y)
```

##Klasyfikatory



####1. Regresja logistyczna

Pierwszym testowanym klasyfikatorem jest regresja logistyczna
```{r,message=FALSE,warning=FALSE}
Regresja <- glm(death1y~.,Zbior_Trening, family="binomial")
summary(Regresja)
```

Ostatnia z kolumn opisuj¹cych zmienne objaœniaj¹ce mówi o istotnoœci ka¿dej ze zmiennych. Jak widzimy wiêkszoœæ zmiennych model uznaje jednak za niestotne, spróbujemy zatem poprawiæ nasz¹ regresjê funkcj¹ `step`

####2. Poprawiona regresja logistyczna metod¹ backward
```{r,message=FALSE,warning=FALSE,results="hide"}
Reg_back<-step(Regresja,method="backward")
```
```{r}
summary(Reg_back)
```

####3. Drzewo z pakietu party

Kolejnym narzêdziem pomocnym w klasyfikacji s¹ drzewa decyzyjne, które charakteryzuj¹ siê doœæ s³ab¹ stabilnoœci¹
```{r,message=FALSE,warning=FALSE}
library("party")
Drzewo <- ctree(death1y~., data=Zb, controls= ctree_control(testtype = "Bonferroni",mincriterion = 0.5))
plot(Drzewo)
```


####4. Las

Klasyfikatorem o wiêkszej stabilnoœci od drzew jest las 
```{r,message=FALSE,warning=FALSE}
library("randomForest")
set.seed(1)
Las<-randomForest(death1y~.,data=Zb,importance=TRUE,proximity=TRUE)
Las
```

####5. Naiwny Bayes

Ostatnim testowanym przez nas klasyfikatorem bêdzie naiwny klasyfikator Bayesowski.Zak³ada on jednak, ¿e ³¹czna gestoœæ jest iloczynem gêstoœci brzegowych. W celu przetestowania jakoœci tego modelu pominiemy to za³o¿enie 
```{r,message=FALSE,warning=FALSE}
library("e1071")
Bayes <- naiveBayes(death1y~.,Zb)
Bayes
```


Aby porównaæ stworzone klasyfikatory u¿yjemy kilku narzêdzi: tablic kontygencji,K-fold cross-walidacjji oraz narysujemy krzywe ROC

##Ocena klasyfikatorów

###Tabele kontyngencji

Najpierw konstruujemy przewidywan¹ na podstawie skonstruowanych klasyfikatorów œmiertelnoœæ dla zbioru testowego przy pomocy `predict`. Potem zbudujemy odpowiadaj¹ce im tablice


####1. Dla regresji logistycznej
```{r,message=FALSE,warning=FALSE}
predykcja1 <- predict(Regresja, Zbior_Testowy,type="response")
predykcja1 <- round(predykcja1,digits=0)
table(predykcja = predykcja1,Tabela = Zbior_Testowy$death1y)
```

####2. Dla poprawionej regresji logistycznej metod¹ backward
```{r,message=FALSE,warning=FALSE}
predykcja2 <- predict(Reg_back, Zbior_Testowy,type="response")
predykcja2 <- round(predykcja2,digits=0)
table(predykcja = predykcja2,Tabela = Zbior_Testowy$death1y)
```

####3. Dla drzewa z pakietu party
```{r,message=FALSE,warning=FALSE}
predykcja3 <- predict(Drzewo, Zbt)
table(predykcja = predykcja3,Tabela = Zbt$death1y)
```

####4. Dla lasu
```{r,message=FALSE,warning=FALSE}
predykcja4 <-  predict(Las, Zbt)
table(predykcja = predykcja4,Tabela = Zbt$death1y)
```

####5. Dla Naiwnego Bayesa
```{r,message=FALSE,warning=FALSE}
predykcja5 <-  predict(Bayes, Zbt)
table(predykcja = predykcja5,Tabela = Zbt$death1y)
```
 
Powy¿sze wynik sugeruj¹, ¿e najlepszym klasyfikatorem jest regresja logistyczna, gdy¿ najlepiej przewidzia³a stan pacjentów


###K-fold cross-walidacja

Kolejn¹ metod¹ porównywania klasyfikatorów jest K-fold cross-walidacja. Wykonujemy j¹ dla k=10. Dzielimy naszych pacjentów na 10 roz³¹cznych grup. W ka¿dym z 10 kroków bierzemy jedn¹ grupê traktuj¹c j¹ jako zbiór testowy, natomiast pozosta³ych jako zbiór treningowy. Dla ka¿dego z dziesiêciu przypadków liczymy b³¹d predykcji i uœredniamy
```{r,message=FALSE,warning=FALSE}

fold <- createFolds(Zbior_Cechy$death1y, k = 10)
```

####1. Dla regresji logistycznej
```{r,message=FALSE,warning=FALSE}
blad1 <- lapply(fold, function(x) {
  predykcja1 <- round(predict(glm(death1y~.,Zbior_Cechy[-x,],family="binomial"),Zbior_Cechy[x,],type="response"),digits =0)
  real1 <- Zbior_Cechy[x, "death1y"]
  mean(abs(predykcja1-real1))
})
mean(as.numeric(blad1))
```

####2. Dla regresji logistycznej poprawionej metod¹ backward
```{r,message=FALSE,warning=FALSE,results="hide"}
blad2 <- lapply(fold, function(x) {
  predykcja2 <- round(predict(step(glm(death1y~.,Zbior_Cechy[-x,],family="binomial"),method="backward"),Zbior_Cechy[x,],type="response"),digits =0)
  real2 <- Zbior_Cechy[x, "death1y"]
  mean(abs(predykcja2-real2))
})
```
```{r}
mean(as.numeric(blad2))
```

####3. Dla drzewa z pakietu party
```{r,message=FALSE,warning=FALSE}
blad3 <- lapply(fold, function(x) {
  predykcja3 <- predict(ctree(death1y~., data=ZC[-x,], controls= ctree_control(testtype = "Bonferroni",mincriterion = 0.5)),ZC[x,])
  real3 <- ZC[x, "death1y"]
  mean(abs(as.numeric(predykcja3)-as.numeric(real3)))
})
mean(as.numeric(blad3))
```

####4. Dla lasu
```{r,message=FALSE,warning=FALSE}
blad4 <- lapply(fold, function(x) {
  predykcja4 <- predict(randomForest(death1y~.,data=ZC[-x,],importance=TRUE,proximity=TRUE),ZC[x,])
  real4 <- ZC[x, "death1y"]
  mean(abs(as.numeric(predykcja4)-as.numeric(real4)))
})
mean(as.numeric(blad4))
```

####5. Dla Naiwnego Bayesa
```{r,message=FALSE,warning=FALSE}
blad5 <- lapply(fold, function(x) {
  predykcja5 <- predict(naiveBayes(death1y~.,ZC[-x,]),ZC[x,])
  real5 <- ZC[x, "death1y"]
  mean(abs(as.numeric(predykcja5)-as.numeric(real5)))
})
mean(as.numeric(blad5))
```

Wyniki b³êdów 10-fold cv
```{r,echo=FALSE}
Errors <- c(Regresja=mean(as.numeric(blad1)), 
          Reg_popr=mean(as.numeric(blad2)), 
          Drzewo=mean(as.numeric(blad3)), 
          Las=mean(as.numeric(blad4)),
          Bayes=mean(as.numeric(blad5)))
Errors
```
Widzimy, ¿e równie¿ najlepiej wypada regresja logistyczna, co pozwala wysun¹æ wnioski i¿ jest to najlepszy klasyfikator 

##Krzywe ROC

Na koniec przedstawimy jeszcze krzywe ROC, aby zobrazowaæ wyniki. Interpretacja krzywych ROC jest doœæ prosta. Im wiêksze pole pod wykresem tym lepszy klasyfikator

```{r,message=FALSE,warning=FALSE,results="hide",echo=FALSE}
library(pROC)
Predykcja1 = predict(Regresja, Zbior_Testowy, type="response")
plot(roc(Zbior_Testowy$death1y, Predykcja1, direction="<"), col = "red", lwd = 3)
par(new=TRUE)
Predykcja2 = predict(Reg_back, Zbior_Testowy, type="response")
plot(roc(Zbior_Testowy$death1y, Predykcja2, direction="<"), col = "blue", lwd = 3)
par(new=TRUE)
Predykcja3 = predict(Drzewo, Zbt)
plot(roc(Zbt$death1y, as.numeric(Predykcja3), direction="<"), col = "brown", lwd = 3)
par(new=TRUE)
Predykcja4 = predict(Las, Zbt)
plot(roc(Zbt$death1y, as.numeric(Predykcja4), direction="<"), col = "green", lwd = 3)
par(new=TRUE)
Predykcja5 = predict(Bayes, Zbt)
plot(roc(Zbt$death1y, as.numeric(Predykcja5), direction="<"), col = "yellow", lwd = 3)
legend(x=0.2, y=0.4, legend = c("Regresja", "Reg_back","Drzewo","Las","Bayes"), col = c("red", "blue","brown", "green","yellow"), lwd=c(3, 3, 3, 3, 3))
```